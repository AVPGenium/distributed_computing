<h2>Задание</h2>

В этом задании предлагается собрать статистику по криминогенной обстановке в разных районах Бостона. В качестве исходных данных используется датасет
https://www.kaggle.com/AnalyzeBoston/crimes-in-boston

С помощью Spark соберите агрегат по районам (поле district) со следующими метриками:
<ol>
<li><b>crimes_total</b> - общее количество преступлений в этом районе</li>
<li><b>crimes_monthly</b> - медиана числа преступлений в месяц в этом районе</li>
<li><b>frequent_crime_types</b> - три самых частых crime_type за всю историю наблюдений в этом районе, объединенных через запятую с одним пробелом “, ” ,
расположенных в порядке убывания частоты <b>crime_type</b> - первая часть NAME из таблицы offense_codes, разбитого по разделителю “-”
(например, если NAME “BURGLARY - COMMERICAL - ATTEMPT”, то crime_type “BURGLARY”)
</li>
<li><b>lat</b> - широта координаты района, расчитанная как среднее по всем широтам инцидентов</li>
<li><b>lng</b> - долгота координаты района, расчитанная как среднее по всем долготам инцидентов</li>
</ol>

Программа должна упаковываться в uber-jar (с помощью sbt-assembly), и запускаться командой
spark-submit --master local[*] --class com.example.BostonCrimesMap /path/to/jar {path/to/crime.csv} {path/to/offense_codes.csv} {path/to/output_folder}
где {...} - аргументы, передаваемые пользователем.
Результатом её выполнения должен быть один файл в формате .parquet в папке path/to/output_folder.
Для джойна со справочником необходимо использовать broadcast.
